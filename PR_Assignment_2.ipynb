{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rJd4oxpuOOs"
      },
      "source": [
        "# Download Datset and Understand the Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NsNs-82juSp0"
      },
      "outputs": [],
      "source": [
        "from pandas.core.arrays.timedeltas import precision_from_unit\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# upload data\n",
        "df_Data = pd.read_csv('kddcup.data.gz')\n",
        "df_test = pd.read_csv('corrected.gz')\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "#Handling categorical features to numerical tcp column in train data and udp column in test data \n",
        "all_categories = set(df_Data['tcp'].unique()).union(set(df_test['udp'].unique()))\n",
        "le.fit(list(all_categories))\n",
        "df_Data['tcp'] = le.transform(df_Data['tcp'])\n",
        "df_test['udp'] = le.transform(df_test['udp'])\n",
        "\n",
        "\n",
        "\n",
        "#Handling categorical features to numerical http column in train data and private column in test data \n",
        "all_categories = set(df_Data['http'].unique()).union(set(df_test['private'].unique()))\n",
        "le.fit(list(all_categories))\n",
        "df_Data['http'] = le.transform(df_Data['http'])\n",
        "df_test['private'] = le.transform(df_test['private'])\n",
        "\n",
        "\n",
        "#Handling categorical features to numerical SF column in train data and SF column in test data \n",
        "all_categories = set(df_Data['SF'].unique()).union(set(df_test['SF'].unique()))\n",
        "le.fit(list(all_categories))\n",
        "df_Data['SF'] = le.transform(df_Data['SF'])\n",
        "df_test['SF'] = le.transform(df_test['SF'])\n",
        "\n",
        "\n",
        "#Handling categorical features to numerical normal column in train data and normal column in test data \n",
        "all_categories = set(df_Data['normal.'].unique()).union(set(df_test['normal.'].unique()))\n",
        "le.fit(list(all_categories))\n",
        "df_Data['normal.'] = le.transform(df_Data['normal.'])\n",
        "df_test['normal.'] = le.transform(df_test['normal.'])\n",
        "\n",
        "\n",
        "\n",
        "train_data = df_Data\n",
        "test_data = df_test\n",
        "\n",
        "# getting labels of train data and test. \n",
        "y_train = train_data['normal.'].values\n",
        "y_test = test_data['normal.'].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDq4S1n1xk21"
      },
      "source": [
        "# Clustering Using K-Means "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yf7WKh0_xnr7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def kmeans(X, k, epsilon):\n",
        "    n_samples, n_features = X.shape\n",
        "    # Randomly choose k data points as the initial centroids\n",
        "    centroids = X[np.random.choice(n_samples, k, replace=False)]\n",
        "    distances = np.zeros((n_samples, k))\n",
        "    labels = np.zeros(n_samples)\n",
        "    old_centroids = np.zeros((k, n_features))\n",
        "\n",
        "   # Continue until the centroids don't change by more than epsilon\n",
        "    while np.linalg.norm(centroids - old_centroids) > epsilon:\n",
        "        old_centroids = centroids.copy()\n",
        "         # Calculate the Euclidean distances from each sample to each centroid\n",
        "        for i in range(k):\n",
        "            distances[:, i] = np.linalg.norm(X - centroids[i], axis=1)\n",
        "         # Assign each sample to the nearest centroid\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        # Update the centroids to be the mean of the samples assigned to them\n",
        "        for i in range(k):\n",
        "            centroids[i] = np.mean(X[labels == i], axis=0)\n",
        "\n",
        "    return labels, centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "ykVHa0aAxzMj",
        "outputId": "8dd37513-caac-49ca-981e-a7330b17d5e6"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2ac8de1a341e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"normal.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-446380b1e883>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(X, k, epsilon)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Randomly choose k data points as the initial centroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5854\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5855\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5856\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([2788525, 3566448, 4511938, 3256748, 4279321, 4761006, 911232], dtype='int64')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "for K in [7, 15, 23, 31, 45]:\n",
        "    labels, centroids = kmeans(train_data.drop([\"normal.\"],axis=1),K,0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFTlJ4oMymKV"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJK-zz3Uyphe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from scipy.stats import entropy\n",
        "\n",
        "precision = precision_score(y_train, labels)\n",
        "recall = recall_score(y_train, labels)\n",
        "f1 = f1_score(y_train, labels)\n",
        "ce = entropy(train_data.drop([\"normal.\"],axis=1), labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vis = []\n",
        "my_dict = {}\n",
        "def dbscan(data, eps, min_samples):\n",
        "    X = data.values\n",
        "    global vis\n",
        "    global my_dict\n",
        "    vis = [0] * len(X)\n",
        "    my_dict = {i: [] for i in range(len(X))}\n",
        "    labels = [0] * len(X)\n",
        "    cluster_id = 0\n",
        "    for i in range(len(X)):\n",
        "        if labels[i] != 0:\n",
        "            continue            \n",
        "        # Find all neighbors of the current point within eps distance\n",
        "        neighbors = get_neighbors(X, i, eps)       \n",
        "        # If the point is not a core point, mark it as an outlier\n",
        "        if len(neighbors) < min_samples:\n",
        "            labels[i] = -1\n",
        "            continue       \n",
        "        # Expand the cluster starting from the current core point\n",
        "        cluster_id += 1\n",
        "        labels[i] = cluster_id\n",
        "        \n",
        "        expand_cluster(X, labels, i, neighbors, eps, min_samples, cluster_id)\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def expand_cluster(X, labels, i, neighbors, eps, min_samples, cluster_id):\n",
        "    \n",
        "    # Loop over each neighbor of the core point\n",
        "    for j in neighbors:\n",
        "        if labels[j] == -1:\n",
        "            labels[j] = cluster_id\n",
        "        elif labels[j] == 0:\n",
        "            labels[j] = cluster_id        \n",
        "            # Find all neighbors of the current point within eps distance\n",
        "            new_neighbors = get_neighbors(X, j, eps)        \n",
        "            # If the point is a core point, add its neighbors to the list of neighbors\n",
        "            if len(new_neighbors) >= min_samples:\n",
        "                neighbors += new_neighbors\n",
        "\n",
        "def get_neighbors(X, i, eps):\n",
        "    global vis\n",
        "    global my_dict\n",
        "    if vis[i] == 1:\n",
        "        return my_dict[i]\n",
        "    neighbors = []\n",
        "    for j in range(len(X)):\n",
        "        if i == j:\n",
        "            continue\n",
        "            \n",
        "        dist = np.linalg.norm(X[i] - X[j])\n",
        "        if dist <= eps:\n",
        "            neighbors.append(j)\n",
        "    vis[i] = 1\n",
        "    my_dict[i] = neighbors\n",
        "    return neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n",
        "# df_copy = train_data.drop(train_data.columns[-1], axis=1)\n",
        "# df_copy.std()\n",
        "train_data_copy, test_data = train_test_split(train_data, test_size=0.95, random_state=42)\n",
        "train_labels = np.array(train_data_copy.iloc[:, -1])\n",
        "print(f\"Training set size: {len(train_data_copy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_labels = dbscan(train_data_copy, 15, 3)\n",
        "print(pred_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
